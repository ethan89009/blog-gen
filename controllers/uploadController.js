const fs = require('fs');
const path = require('path');
const XLSX = require('xlsx');

// Use the built-in fetch from Node.js 20+
/* global fetch */

const MODELS = {
  gemini: {
    apiKey: process.env.GEMINI_API_KEY,
    apiUrl: "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent",
    callLLM: async function(prompt, topics, style) {
      if (!this.apiKey) {
        return "[Gemini API not configured]";
      }
      if (style === "") {
        style = "Provocative , Engaging , Informative";
      }
      const topicsContext = topics.join(", ");
      const instructionStrict = "STRICT IF THE PROMPT contains formating guidlines then ignore these guidelines else follow these GUIDELINES :ONLY USE #,##,### FOR TITLE AND SUB TITLES AND SUB HEADINGS NO OTHER FORMATING , number the topic starting from 1 , below the topic will be one paragraph for one style , before the paragraph put sub heading as style name. paragraph will be regular text. IF THE PROMPT CONTAINS style of writing then ignore the Style: else use the styles. ";
      const textInput = `${instructionStrict}Prompt: "${prompt}"\nTopics: "${topicsContext}"\nStyle: ${style}`;
      const payload = {
        contents: [
          {
            parts: [
              { text: textInput }
            ]
          }
        ]
      };
      const urlWithKey = this.apiUrl + "?key=" + encodeURIComponent(this.apiKey);
      const options = {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(payload)
      };
      const response = await fetch(urlWithKey, options);
      const json = await response.json();
      const text = json.candidates[0].content.parts[0].text;
      return text;
    },
    evalLLM: async function(modelOutput) {
      if (!this.apiKey) {
        return { comment: "[Gemini API not configured]", rating: "0" };
      }
      // Define the evaluator prompt
      const evalPrompt = `You are an evaluator model that must study the output generated by a model. 
this is a output generated by a model i would want you to test the authenticity of this , check the references and make sure there are no error and comment on the quality of the output. Based on the sources and how accurate the data is you will have to generate a json response like this
{
 "comment":"comment on the output",
 "rating":"a value from 0-10 based on how accurate it is",
} 
Rating will be from 0-10 and comment is your advice in about 100 words STRICKLY GENERATE JUST THE JSON RESPONSE . Please dont return 
json
 . ONLY RETURN PLAIN TEXT IN THE FORM OF JSON . I NEED TO PASS THIS STRING TO JSON.parse() in js to parse the output from this response DONT ADD MARKDOWN FORMATING PLEASEE!`;
      const textInput = `${evalPrompt}\nOutput: "${modelOutput}"`;
      const payload = {
        contents: [
          {
            parts: [
              { text: textInput }
            ]
          }
        ]
      };
      const urlWithKey = this.apiUrl + "?key=" + encodeURIComponent(this.apiKey);
      const options = {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(payload)
      };
      const response = await fetch(urlWithKey, options);
      const json = await response.json();
      let evalText = json.candidates[0].content.parts[0].text;
      // Try parsing the output as JSON
      let evalResult;
      try {
        const cleanedText = evalText.replace(/```json/g, '').replace(/```/g, '').trim();
        evalResult = JSON.parse(cleanedText);
      } catch (e) {
        evalResult = { comment: "Error parsing evaluation output", rating: "0" };
      }
      return evalResult;
    }
  },
  perplexity: {
    apiKey: process.env.PERPLEXITY_API_KEY,
    apiUrl: "https://api.perplexity.ai/chat/completions",
    callLLM: async function(prompt, topics, style) {
      if (!this.apiKey) {
        return "[perplexity API not configured]";
      }
      if (style === "") {
        style = "Provocative, Engaging, Informative";
      }
      const topicsContext = topics.join(", ");
      const instructionStrict = "STRICT: If the prompt contains formatting guidelines, ignore them. Otherwise, follow these: Use #, ##, ### for titles and subtitles. Number topics starting from 1. Below each topic, provide one paragraph per style, using the style name as a subheading.";
      const textInput = `${instructionStrict}\nPrompt: "${prompt}"\nTopics: "${topicsContext}"\nStyle: ${style}`;
      const payload = {
        model: "pplx-7b-chat",
        max_tokens: 1024,
        temperature: 0.7,
        messages: [ { role: "user", content: textInput } ]
      };
      const options = {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": "Bearer " + this.apiKey
        },
        body: JSON.stringify(payload)
      };
      const response = await fetch(this.apiUrl, options);
      const json = await response.json();
      const text = json.choices[0].message.content;
      return text;
    }
  },
  claude: {
    apiKey: process.env.ANTHROPIC_API_KEY,
    apiUrl: "https://api.anthropic.com/v1/messages",
    callLLM: async function(prompt, topics, style) {
      if (!this.apiKey) {
        return "[Claude API not configured]";
      }
      if (style === "") {
        style = "Provocative, Engaging, Informative";
      }
      const topicsContext = topics.join(", ");
      const instructionStrict = "STRICT: If the prompt contains formatting guidelines, then ignore them; otherwise, follow these guidelines: Use #, ##, ### for titles and subtitles. Number topics starting from 1. Below each topic, provide one paragraph per style. Use the style name as a subheading before each paragraph.";
      const textInput = `${instructionStrict}\nPrompt: "${prompt}"\nTopics: "${topicsContext}"\nStyle: ${style}`;
      const payload = {
        model: "claude-3-sonnet-20240229",
        max_tokens: 1024,
        temperature: 0.7,
        messages: [ { role: "user", content: textInput } ]
      };
      const options = {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "x-api-key": this.apiKey,
          "anthropic-version": "2023-06-01"
        },
        body: JSON.stringify(payload)
      };
      const response = await fetch(this.apiUrl, options);
      const json = await response.json();
      const text = json.content[0].text;
      return text;
    }
  },
  chatgpt: {
    apiKey: process.env.OPENAI_API_KEY,
    apiUrl: "https://api.openai.com/v1/chat/completions",
    callLLM: async function(prompt, topics, style) {
      if (!this.apiKey) {
        return "[chatgpt API not configured]";
      }
      if (style === "") {
        style = "Provocative, Engaging, Informative";
      }
      const topicsContext = topics.join(", ");
      const instructionStrict = "STRICT: If the prompt contains formatting guidelines, ignore them. Otherwise, follow these: Use #, ##, ### for titles and subtitles. Number topics starting from 1. Below each topic, provide one paragraph per style, using the style name as a subheading.";
      const textInput = `${instructionStrict}\nPrompt: "${prompt}"\nTopics: "${topicsContext}"\nStyle: ${style}`;
      const payload = {
        model: "gpt-4o",
        max_tokens: 1024,
        temperature: 0.7,
        messages: [
          { role: "system", content: "You are an AI writing assistant." },
          { role: "user", content: textInput }
        ]
      };
      const options = {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": "Bearer " + this.apiKey
        },
        body: JSON.stringify(payload)
      };
      const response = await fetch(this.apiUrl, options);
      const json = await response.json();
      const text = json.choices[0].message.content;
      return text;
    }
  }
};

async function generateOutputFromUpload(req, res) {
  try {
    // Validate that both files were uploaded
    if (!req.files || !req.files['promptFile'] || !req.files['topicsFile']) {
      return res.status(400).send({ message: "Please upload both prompt and topics files." });
    }
    const promptFile = req.files['promptFile'][0];
    const topicsFile = req.files['topicsFile'][0];

    const promptText = promptFile.buffer.toString('utf-8');
    const topicsText = topicsFile.buffer.toString('utf-8');

    // Process topics file: split by newline and filter out empty lines
    const topics = topicsText.split("\n").map(line => line.trim()).filter(line => line !== "");

    // Define header row with extra evaluation columns.
    const header = [
      "Topic",
      "Gemini",
      "Gemini_comment_gemini",
      "Gemini_rate_gemini",
      "Perplexity",
      "Gemini_comment_perplexity",
      "Gemini_rate_perplexity",
      "Claude",
      "Gemini_comment_claude",
      "Gemini_rate_claude",
      "ChatGPT",
      "Gemini_comment_chatgpt",
      "Gemini_rate_chatgpt"
    ];
    const data = [header];

    // We will only call the Gemini API since that's the only one configured.
    for (const topic of topics) {
      const row = [];
      row.push(topic);

      // Call Gemini API to generate output
      const geminiOutput = await MODELS.gemini.callLLM(promptText, [topic], "");
      row.push(geminiOutput);

      // Call Gemini evalLLM to evaluate the output
      const evalResult = await MODELS.gemini.evalLLM(geminiOutput);
      row.push(evalResult.comment);
      row.push(evalResult.rating);

      // For other models (Perplexity, Claude, ChatGPT), leave outputs and evaluation columns empty.
      row.push(""); // Perplexity output
      row.push(""); // Gemini_comment_perplexity
      row.push(""); // Gemini_rate_perplexity
      row.push(""); // Claude output
      row.push(""); // Gemini_comment_claude
      row.push(""); // Gemini_rate_claude
      row.push(""); // ChatGPT output
      row.push(""); // Gemini_comment_chatgpt
      row.push(""); // Gemini_rate_chatgpt

      data.push(row);
    }

    // Ensure the outputs folder exists in the project root
    const outputsDir = path.join(__dirname, '..', 'outputs');
    if (!fs.existsSync(outputsDir)) {
      fs.mkdirSync(outputsDir);
    }

    // Create a new workbook and worksheet using xlsx
    const workbook = XLSX.utils.book_new();
    const worksheet = XLSX.utils.aoa_to_sheet(data);
    XLSX.utils.book_append_sheet(workbook, worksheet, "Output");

    // Generate a file name with a timestamp
    const timestamp = Date.now();
    const fileName = `Output_${timestamp}.xlsx`;
    const filePath = path.join(outputsDir, fileName);

    // Write the Excel file to disk
    XLSX.writeFile(workbook, filePath);

    // Respond with success and file info
    res.send({ filePath: filePath, fileUrl: fileName });
  } catch (error) {
    console.error(error);
    res.status(400).send({ message: "error occured" });
  }
}

module.exports = {
  generateOutputFromUpload
};
